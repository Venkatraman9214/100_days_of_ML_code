# 100 days of ML code
This project documents my progress through the 100 days of Machine Learning Challenge.

## Day 1 (July 14, 2018)
I started Jason Brownlee's book "Master Machine Learning Algorithms - Discover how they work and Implement Them from Scratch" and studied 5 chapters. 
1. Introduction to the book
2. Terminology used to talk about data
3. Algorthims learn to map input to output
4. Difference between parametric and non-parametric algorithms. Examples of parametric algorithms include Logistic regression, Linear Discriminant Analysis, Perceptron. Examples of Non-parametric algorithms include Decision Trees, Naive Bayes, Support Vector Machines, Neural Networks.
5. Difference between Supervised, Unsupervised and Semi-Supervised algorithms.

## Day 2
Today I read chapters 6-9.

6. The Bias-Variance Trade-Off 
7. How Bias-Variance trade-off relates to Overfitting and Underfitting. 
8. Crash-Course in Spreadsheet match (skimmed over this chapter)
9. Gradient Descent for machine learning. Gradient Descent is an optimization algorithm used to find the values for parameters (coefficients) of a function that minimize the cost function. Variants include Batch gradient descent and Stochastic Gradient Descent. 

## Day 3
Today I read chapters 10-12.

10. Understanding Linear Regression. 
11. Linear regression Tutorial (implemention in code/day3.R). I also included an example of linear regression model from stats package.
12. Linear Regression with Tutorial using Gradient Descent (I did not implement this)

## Day 4
Today I read chapters 13-14 on Logistic regression. 

## Day 5
Today I read chapters 15-16 on Linear Discriminant Analysis. (implementation in code/day5.R) I usually work with data frames so struggled a bit with tibbles. (NOTE to self: practice using tibbles over data frames)
